camunda:
  bpm:
    admin-user:
      id:  ${CAMUNDA_ID:demo}
      password: ${CAMUNDA_PASSWORD:demo}
      firstName: ${CAMUNDA_FIRST_NAME:Demo}
      lastName: ${CAMUNDA_LAST_NAME:Demo}
    database:
      type: ${CAMUNDA_DATABASE_TYPE:oracle}
      schema-update: ${CAMUNDA_SCHEMA_UPDATE:true}
    job-execution:
      enabled: true
    deployment-resource-pattern: classpath*:bpmn/**/*.bpmn
    auto-deployment-enabled: true
    authorization:
      enabled: true
    application:
      delete-upon-undeploy: false
      scan-for-process-definitions: false
      deploy-changed-only: true
      resume-previous-versions: true
      resume-previous-by: a value

app:
  upload:
    dir: ${UPLOAD_DIR:/}
  files:
    readTime: ${FILES_SCHEDULER_RETENTION:100}

minio:
  endpoint: ${MINIO_ENDPOINT:https://s3.cognive.com/}
  caseFolder: ${MINIO_CASE_FOLDER:tmp}
  fileName: ${MINIO_FILE_NAME:result.json}
  errorCaseFolder: ${MINIO_ERR0R_CASE_FOLDER:errortmp}
  successCaseFolder: ${MINIO_SUCCESS_CASE_FOLDER:successtmp}
  port: ${MINIO_PORT:9000}
  accessKey: ${MINIO_ACCESS_KEY:test-user}
  secretKey: ${MINIO_SECRET_KEY:%T4r#E2w!Q}
  secure: false
  bucket-name: ${MINIO_BUCKET_NAME:test-bucket}
  file-size: ${MINIO_FILE_SIZE:1073741824} #  Here is the maximum file size

spring:
  liquibase:
    enabled: false
  profiles:
    active: ${SPRING_ACTIVE_PROFILES:default}
  jpa:
    show-sql: ${DATABASE_SHOWSQL:true}
    hibernate:
      naming:
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
      ddl-auto: none
    generate-ddl: false
    database-platform: ${DATABASE_PLATFORM:org.hibernate.dialect.Oracle12cDialect}
  datasource:
    hikari:
      jdbc-url: ${DATABASE_URL:jdbc:oracle:thin:@176.9.124.111:1521:orcl}
      username: ${DATABASE_USERNAME:OSADMIN}
      password: ${DATABASE_PASSWORD:Qawsed123}
      driver-class-name: ${DATABASE_DRIVER:oracle.jdbc.OracleDriver}
      schema: ${DATABASE_USERNAME:OSADMIN}

  application:
    name: ${SPRING_APPLICATION_NAME:casernkb}
  cloud:
    stream:
      kafka:
        binder:
          brokers: ${KAFKA_BROKERS}
          configuration:
            max.request.size: 104857600
            security.protocol: ${KAFKA_SECURITY_PROTOCOL}
            ssl.truststore.location: ${KAFKA_SSL_TRUSTSTORE_LOCATION}
            ssl.truststore.password: ${KAFKA_SSL_TRUSTSTORE_PASSWORD}
            ssl.keystore.type: ${KAFKA_SSL_KEYSTORE_TYPE}
            ssl.keystore.location: ${KAFKA_SSL_KEYSTORE_LOCATION}
            ssl.keystore.password: ${KAFKA_SSL_KEYSTORE_PASSWORD}
            ssl.key.password: ${KAFKA_SSL_KEY_PASSWORD}
            key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
            key.serializer: org.apache.kafka.common.serialization.StringSerializer
      bindings:
        commonMessageInput-in-0:
          destination: ${TOPIC_CASE_REQUEST}
          group: case-rnkb
          binder: kafka
        outMessage-out-0:
          destination: ${TOPIC_CASE_OUT}
          group: case-rnkb
          binder: kafka
      function:
        definition: commonMessageInput

server:
  port: ${SERVER_PORT:8193}
  message-mapping:
    message-case: ${TOPIC_CASE_REQUEST}
    message-case-out: ${TOPIC_CASE_OUT}

logging:
  level:
    org.springframework: ERROR
    org:
      hibernate:
        type: trace
      camunda:
        bpm: info
    com:
      cognive:
        projects:
          casernkb: DEBUG
          kafkaReader: debug
  pattern:
    file: "%d %p %c{1.} [%t] %m%n"
  file:
    name: ${LOG_PATH:app.log}
    clean-history-on-start: false

